## 软中断问题 6.1-6.2
### 内容
1. 软中断的和系统处理。
2. 高软中断情况下，如何定位问题。
### 软中断概念梳理
1. 中断。中断是内核响应硬件设备触发的请求，调用对应的内核处理函数处理请求。
2. 部分中断，如网络消息到达使得网卡发出中断请求，在内核的处理函数中并不会把消息彻底处理完，而是放入处理队列，在后续中进一步处理。在这个过程中，调用内核处理函数称之为硬中断，处理消息队列称之为软中断。（推测：网络消息的软中断过程大致为内核处理函数设置标志位并将消息放入队列中，内核会定时通过标识位判断是否有消息，如果有则处理队列中的网络消息，协议栈解析协议并且分发到对应进程进行处理）
3. 疑问：文章中谈到中断处理过程会导致无法响应其它中断而导致中断丢失，如果中断处理可能会导致中断丢失，那么这类中断就极不稳定，并且会在频繁的中断处理过程中进一步加剧丢失的情况。这样的设计想来是非常不合理的，系统最重要的是稳定，一个会随便丢数据的系统是不合格的系统，那么Linux是如何设计保证系统的稳定性的呢？
4. 软中断带来的思考。软中断本质是为了削峰处理，把可能集中的请求放入队列中，后续集中处理，避免卡在突然的大量请求中。这个思想在nginx中，Go的Map设计中均有体现。nginx中，当http请求来了时，只是简单的把消息投递到队列中，后续处理队列中的请求。Go的Map扩容时，只创建新的Map，设置标识位，后续每次访问或者新增，迁移部分数据到新的Map中，这样避免单次扩容时，长时间卡在数据迁移上。
### 软中断导致系统CPU升高
1. 表现：总的CPU升高且是系统进程在占用CPU。
2. 分析过程：1.top发现有几个名字前缀为ksoftirqd的系统进程CPU偏高。2.cat /proc/softirqs发现NET_RX(网络消息接收中断中断次数)偏大。3.sar -n DEV 1发现网卡收到了大量的数据包但消耗的流量不多。4.tcpdump查看nginx进程监听端口的网络包。发现有大量来自hping3主机的类型为S的网络包。
3. 工具解析：1./porc/softirqs显示内核每秒各类型中断的次数。2.sar -n DEV 1显示网卡读写数据包的数量和总的流量大小。3.tcpdump查看指定端口指定协议栈收发的协议包的内容和对方主机的地址。4.hping3 -S -p 80 -i u1 ip 给指定ip的主机的80端口发送S类型的网络包，每次发包休息1us。
4. 遗憾：通过hping3压测主机，可以看到明显的有大量的包和流量，但是CPU和NET_RX中断次数没上去。可能的原因是内核处理中断的速度够快，未压测时单个CPU每秒NET_RX的中断次数约1.5-2.5\*10^7,压测时每秒8\*10^4个网络消息包，显然无法造成明显的压力